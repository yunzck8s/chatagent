<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>与 LLM 对话</title>
    <style>
        /* 样式部分保持不变，这里省略以保持简洁 */
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif; display: flex; justify-content: center; background-color: #f4f4f9; margin: 0; padding: 20px; box-sizing: border-box; }
        #chat-container { width: 100%; max-width: 700px; display: flex; flex-direction: column; background: #fff; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); padding: 20px; height: 90vh; }
        h1 { text-align: center; color: #333; margin: 0 0 1rem; }
        #model-selection { display: flex; gap: 1rem; margin-bottom: 1rem; }
        #provider-select, #model-select { padding: 0.5rem 1rem; border-radius: 8px; border: 1px solid #ccc; font-size: 0.9em; flex: 1; }
        #chat-box { flex-grow: 1; border: 1px solid #eaeaea; overflow-y: scroll; padding: 1rem; border-radius: 8px; background-color: #ffffff; display: flex; flex-direction: column; gap: 1rem; margin-bottom: 1rem; }
        #chat-box p { margin: 0; padding: 0.75rem 1rem; border-radius: 12px; line-height: 1.5; max-width: 85%; word-wrap: break-word; }
        .user-message { background-color: #dcf8c6; align-self: flex-end; }
        .bot-message { background-color: #f1f0f0; align-self: flex-start; }
        /* 新增：思考和工具结果的样式 */
        .thought-message { font-style: italic; color: #888; text-align: center; align-self: center; width: 90%; background-color: #fafafa; padding: 0.5rem; border-radius: 6px;}
        .tool-result-message { font-size: 0.9em; color: #333; background-color: #e3f2fd; border-left: 4px solid #2196f3; align-self: center; width: 90%; white-space: pre-wrap; }
        #input-area { display: flex; gap: 1rem; }
        #message-input { flex-grow: 1; padding: 0.75rem 1rem; border-radius: 8px; border: 1px solid #ccc; font-size: 1em; }
        #send-button { padding: 0.75rem 1.5rem; border: none; background-color: #007bff; color: white; border-radius: 8px; cursor: pointer; font-size: 1em; transition: background-color 0.2s; }
        #send-button:hover { background-color: #0056b3; }
        /* 新增：加载指示器样式 */
        .loading-indicator { color: #888; font-style: italic; }
    </style>
</head>
<body>
    <div id="chat-container">
        <h1>与 LLM 对话</h1>
        <div id="model-selection">
            <select id="provider-select">
                <option value="ollama">Ollama</option>
                <option value="deepseek">DeepSeek</option>
            </select>
            <select id="model-select"></select>
        </div>
        <div id="chat-box"></div>
        <div id="input-area">
            <input type="text" id="message-input" placeholder="在这里输入你的消息...">
            <button id="send-button">发送</button>
        </div>
    </div>

<script>
    // --- 1. 获取页面上的元素 ---
    const chatBox = document.getElementById('chat-box');
    const messageInput = document.getElementById('message-input');
    const sendButton = document.getElementById('send-button');
    const providerSelect = document.getElementById('provider-select');
    const modelSelect = document.getElementById('model-select');

    let currentThreadId = null;
    let currentBotParagraph = null;  // 用于跟踪当前机器人的消息段落

    // --- 2. 模型选择逻辑 ---
    async function updateModelOptions() {
        try {
            const response = await fetch('/models');
            if (!response.ok) throw new Error('Failed to fetch models');
            const allModels = await response.json();
            const selectedProvider = providerSelect.value;
            modelSelect.innerHTML = '';
            if (allModels[selectedProvider]) {
                allModels[selectedProvider].forEach(model => {
                    const option = document.createElement('option');
                    option.value = model;
                    option.textContent = model;
                    modelSelect.appendChild(option);
                });
            } else {
                modelSelect.innerHTML = '<option disabled>No models available</option>';
            }
        } catch (error) {
            console.error('Failed to load models:', error);
            modelSelect.innerHTML = '<option disabled>Error loading models</option>';
        }
    }

    // --- 3. 绑定事件 ---
    sendButton.addEventListener('click', sendMessage);
    messageInput.addEventListener('keypress', (e) => {
        if (e.key === 'Enter') sendMessage();
    });
    providerSelect.addEventListener('change', updateModelOptions);
    document.addEventListener('DOMContentLoaded', updateModelOptions);

    // --- 4. 核心发送消息函数 ---
    async function sendMessage() {
        const userMessage = messageInput.value.trim();
        if (!userMessage) return;

        appendMessage('你', userMessage, 'user-message');
        messageInput.value = '';

        // 创建机器人的消息段落
        currentBotParagraph = appendMessage('机器人', '', 'bot-message', true);

        await fetchAndProcessStream('/chat', {
            text: userMessage,
            provider: providerSelect.value,
            model: modelSelect.value,
            thread_id: currentThreadId
        }, currentBotParagraph);
    }

    // --- 5. 流式处理函数 (已更新以适配 create_react_agent) ---
    async function fetchAndProcessStream(endpoint, body, botParagraphElement) {
        try {
            const response = await fetch(endpoint, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(body),
            });

            if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`);

            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            botParagraphElement.innerHTML = '<strong>机器人:</strong> '; // 清空占位符

            while (true) {
                const { done, value } = await reader.read();
                if (done) break;

                const chunk = decoder.decode(value, { stream: true });
                const lines = chunk.split('\n\n');

                for (const line of lines) {
                    if (line.startsWith('data: ')) {
                        const jsonData = JSON.parse(line.substring(6));

                        // 保存或更新会话ID
                        if (jsonData.thread_id && !currentThreadId) {
                            currentThreadId = jsonData.thread_id;
                        }

                        // **核心：根据新的消息类型来显示内容**
                        if (jsonData.type === 'content') {
                            // 添加内容到当前机器人的消息段落
                            botParagraphElement.innerHTML += jsonData.content.replace(/\n/g, '<br>');
                        } else if (jsonData.type === 'thought') {
                            // 对于思考消息，创建新的段落
                            appendMessage('思考', jsonData.content, 'thought-message');
                        } else if (jsonData.type === 'tool_result') {
                            const formattedResult = `执行结果:\n${String(jsonData.content).substring(0, 300)}...`; // 截断过长的结果
                            appendMessage('工具', formattedResult, 'tool-result-message');
                        }
                        scrollToBottom();
                    }
                }
            }
        } catch (error) {
            console.error('Error:', error);
            botParagraphElement.innerHTML += '<span style="color: red;">抱歉，出错了。请检查后端服务是否正常。</span>';
        } finally {
            // 流结束时重置当前机器人段落引用
            currentBotParagraph = null;
        }
    }

    // --- 6. 辅助函数 ---
    function appendMessage(user, text, className, isPlaceholder = false) {
        const p = document.createElement('p');
        p.className = className;
        const strong = document.createElement('strong');
        strong.textContent = `${user}: `;
        p.appendChild(strong);
        if (!isPlaceholder) {
           p.innerHTML += text.replace(/\n/g, '<br>');
        }
        chatBox.appendChild(p);
        scrollToBottom();
        return p;
    }

    function scrollToBottom() {
        chatBox.scrollTop = chatBox.scrollHeight;
    }
</script>
</body>
</html>